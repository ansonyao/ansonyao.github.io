---
layout: post
title:  "How to install scrapy on linux"
date:   2016-04-24 21:07:44 -0700
categories: jekyll update
---

Scrapy is a framework to retrieve information from the webpages. This article shows the process to install Scrapy on a Redhat based linux system. I installed the scrapy on an Redhat EC2 instance but similar process should also work for other linux systems. 

{% highlight bash %}
sudo su
yum groupinstall 'Development Tools'
yum install -y libffi-devel libxslt-devel libxml2-devel openssl-devel python-devel mysql-devel
{% endhighlight %}

The above commands prepared necessary environment to compile the project. Now we are ready to install Scrapy with 

{% highlight bash %}
pip install scrapy
{% endhighlight %}

This command will install the scrapy. Note that when it is successful, we still need to configure the path to make the scrapy command work.

{% highlight bash %}
export PATH=$PATH:/usr/local/bin
{% endhighlight %}

Now we are ready to go. run scrapy!

{% highlight bash %}
scrapy crawl yourspider
{% endhighlight %}

The final step is let the system remember the path of scrapy in future. This can be achieved by adding a file in /etc/profile.d folder. For example, we can add a file scrapy.sh using

{% highlight bash %}
vim /etc/profile.d/scrapy.sh
{% endhighlight %}

Then we add following two lines.
{% highlight bash %}
export scrapy = /usr/local/bin/scrapy
export PATH=$PATH:$scrapy
{% endhighlight %}

Now Linux knows the command scrapy everytime we login. 